{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Kitap2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df['Questions'].tolist()\n",
    "answers = df['Answer'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_encoded = model.encode(questions)\n",
    "answers_encoded = model.encode(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_tensor = torch.from_numpy(questions_encoded)\n",
    "answers_tensor = torch.from_numpy(answers_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the model\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)  # Add a softmax layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)  # Apply the softmax function\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_size = questions_tensor.size(-1)\n",
    "output_size = answers_tensor.size(-1)\n",
    "hidden_size = 32\n",
    "model = DNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()  # Use the cross-entropy loss functionloss_fn = torch.nn.CrossEntropyLoss()  # Use the cross-entropy loss function\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    # Forward pass\n",
    "    logits = model(questions_tensor)\n",
    "    loss = loss_fn(logits, answers_tensor)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(questions_tensor.size(-1), answers_tensor.size(-1)),  # change the number of input units to match the number of rows in the questions tensor\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(answers_tensor.size(-1), 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\berka\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([396, 768])) that is different to the input size (torch.Size([396, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    # Forward pass\n",
    "    logits = model(questions_tensor)\n",
    "    loss = loss_fn(logits, answers_tensor)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0189]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Load the SentenceTransformer model\n",
    "sentence_transformer = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Encode the input question using the SentenceTransformer model\n",
    "input_question = \"I wanna go bathroom\"\n",
    "input_question_encoded = sentence_transformer.encode([input_question])\n",
    "\n",
    "# Convert the NumPy array to a PyTorch tensor\n",
    "input_question_tensor = torch.from_numpy(input_question_encoded)\n",
    "\n",
    "# Make a prediction using the PyTorch model\n",
    "prediction = model(input_question_tensor)\n",
    "\n",
    "# Print the prediction\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the work table in the living room.\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using the PyTorch model\n",
    "prediction = model(input_question_tensor)\n",
    "\n",
    "# Get the index of the highest prediction\n",
    "prediction_index = torch.argmax(prediction).item()\n",
    "\n",
    "# Get the corresponding answer from the list of answers\n",
    "prediction_string = answers[prediction_index]\n",
    "\n",
    "# Print the prediction\n",
    "print(prediction_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012626262626262626\n"
     ]
    }
   ],
   "source": [
    "# Encode the list of answers using the SentenceTransformer model\n",
    "answers_encoded = sentence_transformer.encode(answers)\n",
    "\n",
    "# Convert the encoded answers into a tensor\n",
    "answers_tensor = torch.from_numpy(answers_encoded)\n",
    "\n",
    "# Initialize a counter for the number of correct predictions\n",
    "correct_predictions = 0\n",
    "\n",
    "# Iterate over the list of questions\n",
    "# Iterate over the list of questions\n",
    "for question, answer in zip(questions, answers):\n",
    "    # Encode the question using the SentenceTransformer model\n",
    "    question_encoded = sentence_transformer.encode([question])\n",
    "    \n",
    "    # Convert the encoded question into a tensor\n",
    "    question_tensor = torch.from_numpy(question_encoded)\n",
    "    \n",
    "    # Make a prediction using the PyTorch model\n",
    "    prediction = model(question_tensor)\n",
    "    \n",
    "    # Get the index of the highest prediction\n",
    "    prediction_index = torch.argmax(prediction).item()\n",
    "    \n",
    "    # Get the corresponding answer from the list of answers\n",
    "    prediction_string = answers[prediction_index]\n",
    "    \n",
    "    # Check if the prediction is correct\n",
    "    if prediction_string == answer:\n",
    "        # Increment the counter for correct predictions\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = correct_predictions / len(questions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012626262626262626\n"
     ]
    }
   ],
   "source": [
    "# Encode the answer using the SentenceTransformer model\n",
    "answer_encoded = sentence_transformer.encode([answer])\n",
    "\n",
    "# Convert the encoded answer into a tensor\n",
    "answer_tensor = torch.from_numpy(answer_encoded)\n",
    "\n",
    "# Calculate the cosine similarity between the prediction and the answer\n",
    "similarity = nn.CosineSimilarity(dim=1)(prediction, answer_tensor)\n",
    "if similarity > 0.8:\n",
    "    # Increment the counter for correct predictions\n",
    "    correct_predictions += 1\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = correct_predictions / len(questions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_user = df['Questions'].sample(10, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_user = random_user.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How is it going',\n",
       " 'I am looking comb.',\n",
       " 'Where is the counter?',\n",
       " 'Can you tell me, where can ı find the medicine?',\n",
       " 'Where is the glasses?',\n",
       " 'Do you know where is the cloakroom?',\n",
       " 'Do you know where is the pyjamas?',\n",
       " 'Can you tell me, where can ı find the fabric softener?',\n",
       " 'I am looking bakery.',\n",
       " 'Can you tell me, How can ı go to Bathroom from the Bedroom?']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_question_encoded = sentence_transformer.encode(random_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.45502198e-01,  4.19052511e-01,  2.39110565e+00,\n",
       "         2.63466418e-01,  6.52291924e-02, -3.59421015e-01,\n",
       "         1.34788275e+00, -2.92608351e-01,  6.76919520e-01,\n",
       "        -2.86102921e-01, -1.02284515e+00,  2.31712297e-01,\n",
       "         3.43854398e-01,  6.66127026e-01,  3.13239902e-01,\n",
       "        -3.31460625e-01,  2.23493919e-01, -3.28229964e-01,\n",
       "         1.26276767e+00,  4.98485938e-03, -1.73984766e-01,\n",
       "         2.57861465e-01, -3.97199154e-01, -6.63901269e-01,\n",
       "        -3.22171956e-01,  4.34838802e-01,  1.40895143e-01,\n",
       "         4.56119686e-01, -1.04766095e+00, -3.96824121e-01,\n",
       "         2.39548042e-01, -1.30176261e-01,  3.95919472e-01,\n",
       "        -4.02382463e-01,  2.95519829e-01,  7.87561953e-01,\n",
       "        -2.57563204e-01,  3.67773443e-01,  2.78422236e-01,\n",
       "        -2.03746423e-01, -5.63988946e-02,  9.98828486e-02,\n",
       "         6.50295317e-01, -4.19358760e-01, -6.19155169e-01,\n",
       "         1.89833026e-02,  6.97368324e-01,  1.12973444e-01,\n",
       "        -3.08396220e-01, -9.28729236e-01, -4.05708075e-01,\n",
       "        -6.29177928e-01,  7.62653053e-01,  2.65324265e-01,\n",
       "        -6.35205626e-01, -1.23504326e-02, -6.58065677e-01,\n",
       "        -9.27738190e-01, -8.47063482e-01,  3.71369123e-01,\n",
       "         2.43760813e-02, -3.44858062e-03,  6.45511329e-01,\n",
       "         8.33085835e-01, -7.19640911e-01, -1.88808013e-02,\n",
       "         5.65755188e-01, -2.90045947e-01,  2.65775174e-01,\n",
       "        -3.44672203e-01,  9.88516986e-01, -5.45256138e-01,\n",
       "        -5.31034350e-01,  3.98661137e-01, -1.35783279e+00,\n",
       "        -8.88517380e-01,  5.01915038e-01,  2.91231006e-01,\n",
       "         1.33223486e+00,  1.15691674e+00,  3.20629388e-01,\n",
       "        -3.66104580e-02,  1.01607716e+00,  1.03103995e+00,\n",
       "        -7.85661209e-03,  4.94000465e-01,  2.82079637e-01,\n",
       "         5.35819717e-02, -1.36264956e+00,  2.11267471e-01,\n",
       "         1.15764737e-01,  6.83855832e-01, -1.73064351e-01,\n",
       "        -4.73659754e-01,  3.48253846e-01,  3.92637521e-01,\n",
       "        -2.16240808e-01, -3.56453024e-02,  7.12781608e-01,\n",
       "        -5.74345529e-01, -1.16915751e+00, -4.60251600e-01,\n",
       "        -7.98742831e-01,  1.37903750e-01,  4.57648672e-02,\n",
       "        -2.32465014e-01, -3.29716414e-01, -5.98713100e-01,\n",
       "         4.30547148e-01,  4.83626872e-01,  8.17890823e-01,\n",
       "         4.92650867e-01,  1.11503041e+00, -1.19874319e-02,\n",
       "        -1.86325908e-01,  6.04011603e-02, -1.39551580e+00,\n",
       "        -5.52977109e-03, -1.93287715e-01,  5.10282278e-01,\n",
       "         5.00712812e-01, -5.28604537e-02,  1.87447026e-01,\n",
       "        -5.09305179e-01,  6.25074148e-01, -3.90093446e-01,\n",
       "         6.43033803e-01,  5.15839696e-01, -1.69307077e+00,\n",
       "        -5.07934690e-01,  4.00982380e-01,  1.38180196e+00,\n",
       "         7.67503083e-01, -9.44960415e-01, -1.39169008e-01,\n",
       "         5.02562523e-01,  2.28604630e-01, -6.86554253e-01,\n",
       "        -3.30350310e-01, -3.72534037e-01, -4.94209558e-01,\n",
       "         5.91827810e-01, -2.09663585e-01,  8.23675990e-02,\n",
       "        -2.22979859e-01, -2.13260472e-01,  1.51973397e-01,\n",
       "         5.93181670e-01, -1.10581148e+00, -9.06844810e-03,\n",
       "        -5.04859686e-01,  1.18771589e+00, -5.45439541e-01,\n",
       "        -2.12966084e-01,  4.42459822e-01, -1.33941546e-01,\n",
       "        -1.06387269e+00,  6.12275898e-01,  7.54254520e-01,\n",
       "        -2.70827025e-01, -8.74112770e-02,  6.04963243e-01,\n",
       "        -4.71491903e-01, -6.33653626e-02,  7.55800977e-02,\n",
       "        -9.96133029e-01,  1.65898040e-01,  2.04486728e-01,\n",
       "         3.81989807e-01,  2.23474979e-01,  9.02166188e-01,\n",
       "        -1.32865465e+00, -1.35465696e-01,  3.89549583e-01,\n",
       "         1.56696951e+00, -5.74719727e-01,  8.68142605e-01,\n",
       "         5.43123662e-01,  1.09323514e+00, -2.99929947e-01,\n",
       "        -1.29317166e-02,  4.78645802e-01, -5.19655645e-01,\n",
       "        -1.99808523e-01, -9.86701965e-01, -7.67830074e-01,\n",
       "        -2.63936788e-01, -6.96986616e-02,  4.25667197e-01,\n",
       "        -1.03692494e-01,  5.46348579e-02, -7.14883327e-01,\n",
       "        -2.61175722e-01, -4.29684848e-01, -3.28440309e-01,\n",
       "         3.81220609e-01, -6.15452044e-02,  4.87026453e-01,\n",
       "        -2.23474801e-01,  4.58668441e-01,  5.93103647e-01,\n",
       "         1.60328054e-03,  8.01548243e-01,  1.47864506e-01,\n",
       "        -1.02978505e-01,  7.73898423e-01, -4.91289824e-01,\n",
       "         7.76613951e-01, -1.15427308e-01, -6.63285017e-01,\n",
       "        -1.05576396e+00, -4.27037477e-01,  4.04513121e-01,\n",
       "        -3.18788916e-01, -2.06655562e-01, -1.17895448e+00,\n",
       "         4.52973634e-01, -2.85258532e-01,  9.94822904e-02,\n",
       "         9.69910100e-02,  3.11430365e-01,  3.02126974e-01,\n",
       "        -1.43652439e-01,  7.13179111e-01,  2.62452960e-01,\n",
       "         2.88693726e-01,  6.82306945e-01, -8.54874849e-02,\n",
       "         7.25973070e-01, -3.50272804e-01,  3.58065844e-01,\n",
       "         1.50088534e-01, -5.19122839e-01,  7.45269060e-01,\n",
       "         4.32116985e-01,  7.12592304e-01,  8.44473183e-01,\n",
       "         5.09446502e-01,  4.40710276e-01,  1.44186197e-02,\n",
       "        -3.63031402e-02,  1.10126138e-01,  1.08661973e+00,\n",
       "         8.71112049e-01, -1.23989260e+00, -7.06584990e-01,\n",
       "         2.26617053e-01,  5.91416918e-02, -1.46036610e-01,\n",
       "         1.73554309e-02, -1.17769442e-01, -3.52360874e-01,\n",
       "         1.56397507e-01, -1.11616707e+00,  2.66065359e-01,\n",
       "         3.58008951e-01, -1.04152834e+00,  3.67043525e-01,\n",
       "        -1.27970859e-01, -5.75757444e-01, -1.10584795e-01,\n",
       "         1.30000043e+00, -4.09486502e-01,  3.61816376e-01,\n",
       "        -7.26544634e-02,  2.24907398e-01, -7.56655633e-01,\n",
       "         2.37336323e-01, -3.83749396e-01,  4.11946177e-01,\n",
       "        -3.98691297e-01,  4.32999521e-01, -1.88671708e-01,\n",
       "        -1.11223198e-01, -4.80743766e-01, -2.30786398e-01,\n",
       "         1.27589548e+00,  5.46907723e-01,  9.05131772e-02,\n",
       "        -6.08264983e-01, -4.17412132e-01,  4.53500062e-01,\n",
       "        -1.50934541e+00,  2.31220111e-01, -8.33878100e-01,\n",
       "        -4.99095321e-01, -3.57750267e-01, -7.15271771e-01,\n",
       "        -1.21863461e+00, -4.16784972e-01,  3.71118754e-01,\n",
       "        -1.13317430e+00,  4.35283929e-01, -7.60729134e-01,\n",
       "         1.63514033e-01, -1.16849792e+00,  2.15194643e-01,\n",
       "        -6.15149319e-01, -7.12823629e-01, -5.33952296e-01,\n",
       "        -5.95112264e-01, -2.30083659e-01, -3.49510640e-01,\n",
       "         3.15719098e-01,  2.03304157e-01, -9.14866686e-01,\n",
       "         3.25452417e-01,  4.04480428e-01, -1.03962588e+00,\n",
       "        -9.74790275e-01, -4.48040038e-01,  4.54221636e-01,\n",
       "         2.04801619e-01, -3.08704138e-01, -4.64676470e-01,\n",
       "        -2.52530694e-01, -1.06607163e+00,  1.65234029e+00,\n",
       "         4.99885172e-01, -3.56377870e-01, -3.70830685e-01,\n",
       "         3.50304604e-01,  2.05856964e-01, -4.02159929e-01,\n",
       "         7.47180462e-01, -2.12108061e-01, -9.05985653e-01,\n",
       "         1.86976478e-01, -3.98701072e-01,  8.54312658e-01,\n",
       "         4.80662584e-01, -1.02595389e-01,  3.57214093e-01,\n",
       "         7.75193214e-01,  1.26672387e-02,  1.11426640e+00,\n",
       "        -8.75007689e-01,  3.89134318e-01, -4.15193290e-01,\n",
       "         6.46912158e-01,  1.99473992e-01,  3.78950804e-01,\n",
       "         8.33228886e-01, -2.93084532e-01,  5.89581788e-01,\n",
       "        -7.84059048e-01, -8.13227892e-01, -6.82268441e-01,\n",
       "         6.23316020e-02,  5.09571850e-01,  1.68339416e-01,\n",
       "        -3.48513454e-01, -4.95414048e-01,  2.15311095e-01,\n",
       "        -8.98764610e-01, -4.46678214e-02, -1.21641673e-01,\n",
       "        -2.20674157e-01, -5.74766695e-01, -2.02237085e-01,\n",
       "         1.24398637e+00,  7.97205150e-01,  1.04701303e-01,\n",
       "        -6.21254444e-01, -2.86074251e-01,  2.83699092e-02,\n",
       "         5.61072111e-01, -2.56781608e-01,  3.85012150e-01,\n",
       "        -7.61923313e-01,  3.54214877e-01, -5.95837772e-01,\n",
       "         5.88077724e-01,  5.04255235e-01, -5.61900735e-01,\n",
       "         2.50666291e-02, -2.71384150e-01, -9.03509915e-01,\n",
       "        -1.19964266e+00, -1.13420904e+00, -1.63988695e-01,\n",
       "        -1.00492883e+00,  4.36874241e-01,  5.33952177e-01,\n",
       "        -6.42429665e-02,  3.79268557e-01,  4.84832764e-01,\n",
       "        -3.69916439e-01,  4.07614589e-01, -6.06862366e-01,\n",
       "        -3.84568214e-01,  8.39897573e-01, -3.24052662e-01,\n",
       "        -8.70482028e-01,  2.71772325e-01, -1.86122787e+00,\n",
       "         1.01571286e+00,  6.07433617e-01,  3.80524755e-01,\n",
       "         6.08421624e-01, -3.67621809e-01, -5.89125097e-01,\n",
       "        -4.65487629e-01,  3.85585666e-01, -3.41863960e-01,\n",
       "        -5.51365733e-01,  6.28974617e-01, -7.45578587e-01,\n",
       "        -2.10632607e-01, -1.23097897e-01, -1.53000608e-01,\n",
       "        -1.55981407e-01,  1.79989219e-01, -2.67963856e-01,\n",
       "        -3.83858174e-01,  7.43730247e-01,  4.48796391e-01,\n",
       "        -8.88036907e-01, -7.97443449e-01,  2.85485029e-01,\n",
       "        -2.24284172e-01, -5.56598365e-01, -5.45252740e-01,\n",
       "        -5.64275980e-02, -3.49270105e-01,  1.89106867e-01,\n",
       "         6.41682267e-01,  1.32252514e+00,  6.15466356e-01,\n",
       "         1.76570967e-01, -6.52409971e-01, -2.47548103e-01,\n",
       "        -7.09675014e-01,  9.45584953e-01,  8.73921096e-01,\n",
       "        -2.41771922e-01,  7.24767864e-01,  7.64682770e-01,\n",
       "         5.29345036e-01, -3.66568714e-02,  4.41853285e-01,\n",
       "        -7.68449962e-01,  2.50193000e-01,  1.76484883e-01,\n",
       "        -2.10112453e-01, -2.22996280e-01, -1.01639116e+00,\n",
       "        -8.65606010e-01, -1.79326370e-01, -5.95517457e-01,\n",
       "         2.66120791e-01,  1.17346914e-02, -4.38577533e-01,\n",
       "         5.77989936e-01,  2.13228896e-01, -1.06219880e-01,\n",
       "        -1.54415190e-01,  1.62171125e+00,  4.29676957e-02,\n",
       "        -8.08224142e-01,  5.32081187e-01,  4.60486054e-01,\n",
       "         3.24097723e-01,  3.00909311e-01,  6.83190525e-01,\n",
       "         5.43579996e-01, -2.82284290e-01,  5.86809278e-01,\n",
       "        -5.41156113e-01,  2.56393105e-01,  1.47900060e-01,\n",
       "         5.85584223e-01,  1.74285069e-01,  7.62514412e-01,\n",
       "        -2.29675770e-02, -1.01064074e+00, -9.63588417e-01,\n",
       "         6.17898047e-01,  6.45916224e-01,  7.61978149e-01,\n",
       "        -1.92221284e-01,  4.76176411e-01,  1.01410516e-01,\n",
       "        -9.74919572e-02, -9.17054892e-01,  1.71895421e+00,\n",
       "         3.69668216e-01,  1.93584099e-01,  1.09566903e+00,\n",
       "        -1.03448713e+00, -8.64258334e-02, -1.11957395e+00,\n",
       "        -2.58207798e-01, -1.09608054e+00, -5.68802297e-01,\n",
       "        -1.42415273e+00, -6.33312404e-01,  1.65889964e-01,\n",
       "         6.23175681e-01,  5.09977877e-01,  3.75032812e-01,\n",
       "         2.54657358e-01,  4.09803241e-01, -3.89629036e-01,\n",
       "         2.57419676e-01,  5.37771881e-01, -1.38387633e-02,\n",
       "        -1.62742808e-01,  7.10140646e-01,  7.60392725e-01,\n",
       "        -1.05454981e+00,  7.63033330e-01,  1.02467632e+00,\n",
       "        -1.18769777e+00, -4.52010065e-01,  1.21548556e-01,\n",
       "         2.16578916e-01,  7.09021866e-01,  8.61476883e-02,\n",
       "         2.85527170e-01,  1.69860289e-01,  3.10231805e-01,\n",
       "        -3.98046613e-01, -4.29526687e-01, -5.48392236e-01,\n",
       "        -1.44215718e-01,  1.44647300e+00,  1.18065573e-01,\n",
       "         6.38148487e-01, -7.16030598e-01,  3.30476463e-02,\n",
       "        -2.59145200e-01, -8.60192001e-01, -1.05311446e-01,\n",
       "        -5.88430882e-01,  5.77604711e-01, -1.12458777e+00,\n",
       "        -1.85385063e-01, -2.28017017e-01, -3.49823833e-01,\n",
       "         7.96977103e-01,  4.96708900e-01,  7.90638626e-01,\n",
       "        -8.22335780e-01, -7.98892438e-01,  8.97891283e-01,\n",
       "        -3.76992613e-01, -6.22006118e-01,  4.11325485e-01,\n",
       "        -3.31745178e-01, -3.75188619e-01, -4.97591309e-02,\n",
       "        -3.50189321e-02, -2.87497431e-01, -1.51085413e+00,\n",
       "        -2.96505690e-01, -2.95185924e-01,  4.89032835e-01,\n",
       "        -5.96063696e-02, -9.85747814e-01, -1.66322216e-02,\n",
       "        -3.54020357e-01,  7.99104571e-04, -1.43564092e-02,\n",
       "         4.32561599e-02,  6.30947113e-01,  1.03878276e-02,\n",
       "         1.86762676e-01,  1.56036196e-02,  1.27086714e-01,\n",
       "        -3.73143762e-01, -5.17703772e-01,  2.45505691e-01,\n",
       "         5.11766255e-01, -2.86520928e-01, -2.83449739e-01,\n",
       "        -3.59253794e-01, -5.98707438e-01, -5.22461176e-01,\n",
       "        -1.61623731e-01, -3.28533024e-01,  1.87543586e-01,\n",
       "         5.93797922e-01,  1.50632918e-01, -1.17594099e+00,\n",
       "        -1.19829810e+00,  7.95444548e-01, -8.53315651e-01,\n",
       "         8.93765017e-02, -3.03403616e-01, -1.50982842e-01,\n",
       "         3.24593753e-01,  9.50035334e-01, -4.55691576e-01,\n",
       "        -3.08508307e-01, -3.72880101e-01,  3.02094489e-01,\n",
       "         1.15682292e+00,  2.81419367e-01, -1.57899693e-01,\n",
       "        -4.38625179e-02,  4.52509612e-01, -5.88694036e-01,\n",
       "         4.33231920e-01, -1.31733669e-02,  7.40731776e-01,\n",
       "        -5.38421214e-01, -4.23981398e-01,  3.41032296e-01,\n",
       "         3.15852314e-02,  1.27771005e-01, -7.66260803e-01,\n",
       "         1.92719176e-01, -2.25851133e-01, -3.70871387e-02,\n",
       "        -1.43140948e+00, -8.01451981e-01,  2.03393281e-01,\n",
       "         1.02516091e+00, -4.57330942e-01,  1.36436746e-01,\n",
       "        -5.27447164e-01, -3.61920260e-02,  1.00335145e+00,\n",
       "         7.24961519e-01, -6.73629284e-01, -4.06556994e-01,\n",
       "        -5.92712104e-01,  4.17111844e-01, -4.93984431e-01,\n",
       "         1.02753031e+00,  5.84919512e-01,  9.24519837e-01,\n",
       "        -7.05337822e-01, -4.71924663e-01,  1.19844997e+00,\n",
       "         1.43597066e-01, -4.14666682e-01,  3.43532652e-01,\n",
       "        -1.02391839e+00,  2.58197904e-01,  2.03867316e-01,\n",
       "         1.32850900e-01, -2.89918244e-01, -2.30508253e-01,\n",
       "        -3.78258973e-01,  1.20112956e-01,  2.44357094e-01,\n",
       "         9.10552561e-01,  2.27204084e-01, -5.36157668e-01,\n",
       "        -5.61469316e-01,  4.48145837e-01,  7.55880654e-01,\n",
       "         2.54674077e-01, -7.50203133e-01,  2.11520288e-02,\n",
       "         3.04691494e-01, -6.19982481e-01, -2.40254894e-01,\n",
       "         6.29528284e-01,  6.28764033e-02,  3.14456433e-01,\n",
       "         4.62483644e-01,  1.12564385e+00, -9.10866261e-01,\n",
       "         3.28247547e-01, -2.18086913e-01, -4.14881617e-01,\n",
       "        -9.97025073e-01,  1.98758915e-01,  1.86531737e-01,\n",
       "        -7.45749474e-01, -2.42617652e-01, -7.85578430e-01,\n",
       "        -4.23972636e-01,  1.29529536e+00, -1.00993775e-01,\n",
       "        -4.31159228e-01,  5.24616778e-01,  4.08367157e-01,\n",
       "         2.45804146e-01,  7.56751955e-01, -3.24400723e-01,\n",
       "        -1.53208733e-01, -4.57187295e-01,  3.52789983e-02,\n",
       "        -4.91446972e-01,  7.51738131e-01,  7.02150643e-01,\n",
       "         3.00193518e-01, -1.97581604e-01, -1.72038332e-01,\n",
       "        -3.90682548e-01,  7.71073520e-01,  1.52579889e-01,\n",
       "        -4.81577635e-01, -1.26107514e-01, -5.18677294e-01,\n",
       "         2.38402322e-01, -8.83471966e-01, -3.07830304e-01,\n",
       "        -2.41173863e-01, -8.37474644e-01, -6.94566309e-01,\n",
       "        -7.84251690e-01,  2.75380015e-02, -4.60346788e-01,\n",
       "        -4.00617361e-01,  1.42686412e-01, -3.09952825e-01,\n",
       "         2.02746606e+00, -3.79120670e-02,  5.23606122e-01,\n",
       "        -1.71101987e+00, -1.81079209e-01,  6.29637778e-01,\n",
       "         3.16576362e-02,  3.22691411e-01, -4.24270838e-01,\n",
       "        -3.11119735e-01,  6.78620562e-02, -1.54124513e-01,\n",
       "         2.45149374e-01, -6.71166852e-02, -7.48893082e-01,\n",
       "         5.62893450e-01, -3.05762500e-01, -1.56431179e-02,\n",
       "        -3.87324810e-01, -1.11017890e-01,  3.85162383e-02,\n",
       "        -9.93384778e-01, -7.07934320e-04,  7.84374714e-01,\n",
       "        -3.47577959e-01, -1.50594577e-01,  3.25407356e-01,\n",
       "        -6.41289055e-01, -2.24370316e-01, -7.88283885e-01,\n",
       "         8.16644609e-01, -4.71913725e-01,  2.42173672e-01,\n",
       "        -5.65262258e-01, -3.21110487e-01,  6.55689061e-01,\n",
       "         1.16189085e-01, -3.07144988e-02,  2.72434741e-01,\n",
       "         8.33711684e-01,  6.25830829e-01, -6.08076155e-01,\n",
       "        -5.86898625e-01,  3.73893343e-02,  2.96347320e-01,\n",
       "        -4.27202314e-01, -1.44365981e-01,  3.08260351e-01,\n",
       "        -8.67488980e-02, -7.66247436e-02,  7.76135698e-02,\n",
       "        -1.29704624e-01, -4.87336546e-01,  1.73650697e-01,\n",
       "        -6.11630023e-01, -8.38528097e-01,  9.00528133e-01]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_question_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_question_tensor = torch.from_numpy(input_question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(input_question_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0189]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "939426be350ea136d7702cb38d9d1c611a2da7982b737f0b7151fc28273a1a91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
